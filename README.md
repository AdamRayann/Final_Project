# Final_Project

# MOODSense - Real-Time Emotion Recognition and Feedback System

MOODSense is an advanced emotion recognition application that combines deep learning, computer vision, and generative models to deliver real-time emotional analysis through facial expression and voice detection. Built with a user-friendly interface, MOODSense can operate in real-time or analyze uploaded images and audio, providing users with a comprehensive emotional insight. The system offers an explanation for detected emotions and provides actionable suggestions for mood improvement, enhancing user experience and emotional awareness.

## Table of Contents

- [Features](#features)
- [Technologies Used](#technologies-used)
- [User Experience](#user-experience)
- [Applications](#applications)
- [Getting Started](#getting-started)
- [Docker Usage](#docker-usage)
- [License](#license)

---

**__________________________________________________________________________________**  
**|[Watch the Project Overview Video Here!](https://youtu.be/oIidj_s_qN0)|**  
**__________________________________________________________________________________**  

## Features

- **Real-Time and Batch Emotion Detection**: Detect emotions in real-time or through uploaded images/audio.
- **Multi-Face and Voice Recognition**: Simultaneous detection of multiple faces or voices, summarizing overall emotional states.
- **Emotion Explanation and Suggestions**: Explains detected emotions and offers suggestions to improve mood.
- **Modern Interface**: User-friendly and engaging interface for smooth navigation and interaction.

## Technologies Used

- **Deep Learning Models**: Convolutional Neural Networks (CNNs) for facial expression recognition.
- **Computer Vision**: Haar Cascade for face detection, enabling accurate real-time recognition.
- **Generative Models**: Whisper for audio transcription and Llama for voice emotion analysis.
- **Docker**: Containerized environment ensuring consistent deployment and streamlined sharing.
- **Python Libraries**: Includes libraries like OpenCV, NumPy, and PIL for image and audio processing.

## User Experience

MOODSense provides a personalized emotional experience by detecting emotions, explaining the reasons for these interpretations, and offering ways to improve user mood. Users can choose to analyze emotions live or upload media files, making it a versatile tool suitable for various applications. Multiple faces and voices can be processed simultaneously, with the summarized results displayed clearly in the intuitive interface.

## Applications

1. **Personal Mood Management**: Track emotions and receive mood-enhancing suggestions.
2. **Educational and Research**: Use for educational purposes in emotional intelligence training or psychological research.
3. **Customer Service**: Enhance customer interactions by gauging and responding to emotional cues.

## Getting Started

### Prerequisites

- **conda Python 3.7.16** installed on your system.
- **Docker** installed for containerized deployment.

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/AdamRayann/Final_Project.git


2. **Install dependencies:**
    ```bash
    pip install -r requirements.txt

3. **Start Docker:**

    Start Docker on your system 

4. **Run the Application**:

    Launch the application to experience MOODSense's services . The first run may take some time to set up, depending on your internet speed. So, relax and grab a mug of coffee while it loads ;D



